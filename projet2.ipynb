{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet Maison 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import des modules usuels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement et traitement des données\n",
    "GEO = pd.read_csv(\"correspondance-code-insee-code-postal.csv\",\n",
    "                   sep=';',\n",
    "                   usecols=range(11),\n",
    "                   index_col=\"Code INSEE\")\n",
    "\n",
    "lat_lon = GEO['geo_point_2d']\n",
    "array = lat_lon.to_numpy()\n",
    "lat, lon = [],[]\n",
    "for element in array :  # découpage de la série geo_point_2d en latitude et longitude\n",
    "    element = element.split(',')\n",
    "    lat.append(float(element[0]))\n",
    "    lon.append(float(element[1]))\n",
    "\n",
    "GEO['Latitude'] = lat\n",
    "GEO['Longitude'] = lon\n",
    "GEO['cp_ville'] = GEO['Code Postal'] + \" \" + GEO['Commune']\n",
    "    \n",
    "# A COMPLETER avec les colonnes\n",
    "# - lat, lon : latitude et longitude des communes\n",
    "# - cp_ville : Code Postal + \" \" + \"Commune\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie A**\n",
    "\n",
    "- Compléter le chargement des données en ajoutant au dataframe `GEO`\n",
    "    - les colonnes \"lat\" et \"lon\" avec la latitude et la longitude des communes\n",
    "    - une colonne \"cp_ville\" avec le Code Postal + un espace + et le nom de la Commune\n",
    "- Ecrire une fonction `search_city(lat, lon)` qui retourne le \"cp_ville\" de la commune la plus proche d'un point à partir de sa latitude et sa longitude.\n",
    "- Ecrire une fonction `dms2dec(deg, min, sec)` qui convertit les degrés, minutes, secondes en valeur numérique pour pouvoir utiliser la fonction précédente avec un GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31350 BOULOGNE-SUR-GESSE\n"
     ]
    }
   ],
   "source": [
    "# fonction recherche de ville\n",
    "\n",
    "\n",
    "\n",
    "def search_city(lat, long):\n",
    "    GEO['Distance'] = (GEO['Latitude'] - lat)**2 + (GEO['Longitude'] - long)**2 # calcul de la distance euclidienne entre les deux paires de cordonnées\n",
    "    return GEO['cp_ville'][GEO['Distance'].idxmin()]\n",
    "\n",
    "\n",
    "    \n",
    "print(search_city(43.3,0.65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conversion degrés, minutes, secondes => décimal\n",
    "def dms2dec(deg, mn, sec):\n",
    "    return deg + mn/60 + sec/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'71330 BOSJEAN'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on applique la fonction à une coordonnée tirée au hasard\n",
    "np.random.seed(0)\n",
    "a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "lat = np.random.uniform(a, b)\n",
    "a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "lon = np.random.uniform(a, b)\n",
    "\n",
    "search_city(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91120 PALAISEAU'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# à partir de coordonnées GPS précises\n",
    "search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie B**\n",
    "\n",
    "La colonne \"geo_shape\" comporte des chaines de catactères au format JSON. Elles représentent les formes géométriques des communes qui sont soit des polygones soit composées de plusieurs polygones.\n",
    "\n",
    "- Utiliser la librairie Python **json** pour parser les valeurs de la colonne \"geo_shape\" et mettre le résultat (`Series`) dans la variable `GEO_SHAPE`.\n",
    "- Ecrire une fonction `get_types()` qui retourne le décompte (`value_counts()`) des valeurs accédées avec la clé \"type\".\n",
    "- Ecrire une fonction `get_coordinates_len()` qui retourne le décompte (`value_counts()`) des longueurs des listes accédées avec la clé \"coordinates\".\n",
    "- Ecrire une fonction `get_most_complex_city()` qui retourne la commune est constituée du plus grand nombre de polygones ?\n",
    "- Ecrire une fonction `get_nb_cities_2_polygons()` qui retourne  le nombre de villes qui sont de type \"Polygon\" mais dont la longueur des listes accédées avec la clé \"coordinates\" vaut 2 ?\n",
    "- **Facultatif :**\n",
    "- Pour ces villes vérifier que le premier polygone contient bien le second (enclave). NB : on pourra installer la librairie **shapely**, utiliser la classe Polygon de **shapely.geometry**  et la méthode `contains()`. Sur Windows **shapely** peut nécessiter d'installer manuellement la dll \"geos_c.dll\" dans le répertoire \"Library/bin\" de votre environnement Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEO_SHAPE\n",
    "\n",
    "# La variable GEO_SHAPE doit contenir une Serie\n",
    "# correspondant aux valeurs de la colonne \"geo_shape\" parsées avec la librairie json\n",
    "GEO_SHAPE = pd.Series(dtype=object)\n",
    "\n",
    "import json\n",
    "shape = []\n",
    "for element in GEO['geo_shape']:\n",
    "    element = json.loads(element)\n",
    "    element = element[\"type\"]\n",
    "    shape.append(element)\n",
    "\n",
    "GEO_SHAPE = pd.Series(shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon         36670.0\n",
      "MultiPolygon       72.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# value_counts des valeurs \"type\"\n",
    "def get_types():\n",
    "    dico = GEO_SHAPE.value_counts('type')\n",
    "    return dico*len(GEO_SHAPE)\n",
    "print(get_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts des longueurs de \"coordinates\"\n",
    "def get_coordinates_len():\n",
    "    dico = {}\n",
    "    for element in GEO['geo_shape']:\n",
    "        element = json.loads(element)\n",
    "        if len(element[\"coordinates\"]) in dico :\n",
    "            dico[len(element[\"coordinates\"])] += 1\n",
    "        else :\n",
    "            dico[len(element[\"coordinates\"])] = 1  \n",
    "    return(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commune constituée du plus grand nombre de polygones\n",
    "def get_most_complex_city():\n",
    "    length_list = []\n",
    "    for element in GEO['geo_shape']:\n",
    "        element = json.loads(element)\n",
    "        length_list.append(len(element['coordinates']))\n",
    "    return(GEO['cp_ville'][length_list.index(max(length_list))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# nombre de villes qui sont de type \"Polygon\" mais dont la longueur des listes accédées avec la clé \"coordinates\" vaut 2 \n",
    "def get_nb_cities_2_polygons():\n",
    "    dico_length = []\n",
    "    c=0 #compteur des communes 'Polygon' de longueur > 1\n",
    "    for element in GEO['geo_shape']:\n",
    "        element = json.loads(element)\n",
    "        if element[\"type\"] == 'Polygon' and len(element[\"coordinates\"]) > 1 : #recherche des communes de type Polygon constituées de plusieurs polygones\n",
    "            c +=1 \n",
    "    return c\n",
    "                                              \n",
    "\n",
    "print(get_nb_cities_2_polygons())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "import unittest\n",
    "\n",
    "class Session2Test(unittest.TestCase):\n",
    "    \n",
    "    def test_partie_A1(self):\n",
    "        # on applique la fonction cherche_ville() à une coordonnée tirée au hasard\n",
    "        np.random.seed(0)\n",
    "        a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "        lat = np.random.uniform(a, b)\n",
    "        a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "        lon = np.random.uniform(a, b)\n",
    "\n",
    "        cp_ville = search_city(lat, lon)\n",
    "        self.assertEqual(cp_ville, \"71330 BOSJEAN\")\n",
    "        \n",
    "    def test_partie_A2(self):\n",
    "        # à partir de coordonnées GPS précises\n",
    "        cp_ville = search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))\n",
    "        self.assertEqual(cp_ville, \"91120 PALAISEAU\")\n",
    "        \n",
    "    def test_partie_B1(self):\n",
    "        # check types\n",
    "        dico = get_types()\n",
    "        self.assertEqual(dico[\"Polygon\"], 36670)\n",
    "        self.assertEqual(dico[\"MultiPolygon\"], 72)\n",
    "        \n",
    "    def test_partie_B2(self):\n",
    "        # check coordinates len\n",
    "        dico = get_coordinates_len()\n",
    "        self.assertEqual(dico[1], 36660)\n",
    "        self.assertEqual(dico[2], 80)\n",
    "       \n",
    "    def test_partie_B3(self):\n",
    "        # check most complex city\n",
    "        cp_ville = get_most_complex_city()\n",
    "        self.assertEqual(cp_ville, \"83400 HYERES\")\n",
    "        \n",
    "    def test_partie_B4(self):\n",
    "        # check nb cities 2 polygons\n",
    "        nb = get_nb_cities_2_polygons()\n",
    "        self.assertEqual(nb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_partie_A1 (__main__.Session2Test) ... ok\n",
      "test_partie_A2 (__main__.Session2Test) ... ok\n",
      "test_partie_B1 (__main__.Session2Test) ... ok\n",
      "test_partie_B2 (__main__.Session2Test) ... ok\n",
      "test_partie_B3 (__main__.Session2Test) ... ok\n",
      "test_partie_B4 (__main__.Session2Test) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 1.598s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Session2Test)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)\n",
    "    \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "da285fe5a810ca0135619b9907a5d7dd4904f6a625a227faa5b9da2e901ab7c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
